{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c8c6f65",
   "metadata": {},
   "source": [
    "### Generate data with ST\n",
    "\n",
    "For this we only used the data proportioned by Ye Yuan & Ziv Bar-Joseph. They used 913 cells, with spatial location and transcriptome for each one. \n",
    "\n",
    "Files used:\n",
    "* cortex_svz_cellcentroids.csv : contains cells id, coordinates and corresponding region\n",
    "* cortex_annotation: contain cells id and cell type\n",
    "* cortex_svs_counts.cvs: a matrix wuth the raw gene counts. It had 913 rows corresponding to each cell. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0132d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "from scipy import sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7e7fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalized_adjacency(A, symmetric=True):\n",
    "    \"\"\"\n",
    "    Based on spektral from prevoius versions .\n",
    "    Normalizes the given adjacency matrix using the degree matrix as \\(\\D^{-1/2}\\A\\D^{-1/2}\\) \n",
    "    Assuming a symetric matrix\n",
    "    params: A (adjency matrix)\n",
    "    \"\"\"\n",
    "    normalized_D = degree_power(A, -0.5)\n",
    "    return normalized_D.dot(A).dot(normalized_D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a390e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_power(A, k):\n",
    "    \"\"\"\n",
    "    Based on spektral from prevoius versions \n",
    "    Computes \\(\\D^{k}\\) from the given adjacency matrix. Useful for computing\n",
    "    normalised Laplacian.\n",
    "    :param A: rank 2 array or sparse matrix.\n",
    "    :param k: exponent to which elevate the degree matrix.\n",
    "    :return: A dense array\n",
    "    \"\"\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        degrees = np.power(np.array(A.sum(1)), k).ravel()\n",
    "    degrees[np.isinf(degrees)] = 0.0\n",
    "    if sp.issparse(A):\n",
    "        D = sp.diags(degrees)\n",
    "    else:\n",
    "        D = np.diag(degrees)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7819e62c",
   "metadata": {},
   "source": [
    "The file cortex_svz_cellcentroids.csv will generate a list of the cells processed . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2beb586",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.path.abspath('.')\n",
    "cortex_svz_cellcentroids = pd.read_csv(current_path+'/seqfish_plus/cortex_svz_cellcentroids.csv')\n",
    "############# get batch adjacent matrix\n",
    "cell_view_list = []\n",
    "for view_num in range(7):\n",
    "    cell_view = cortex_svz_cellcentroids[cortex_svz_cellcentroids['Field of View']==view_num]\n",
    "    cell_view_list.append(cell_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176d868f",
   "metadata": {},
   "source": [
    "We now calculate the distace matrix, by looking at the coordinates, finally making a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce0b2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating distance matrix, it takes a while\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "distance_list_list = []\n",
    "distance_list_list_2 = []\n",
    "print ('calculating distance matrix, it takes a while')\n",
    "for view_num in range(7):\n",
    "    print (view_num)\n",
    "    cell_view = cell_view_list[view_num]\n",
    "    distance_list = []\n",
    "    for j in range(cell_view.shape[0]):\n",
    "        for i in range (cell_view.shape[0]):\n",
    "            if i!=j:\n",
    "                distance_list.append(np.linalg.norm(cell_view.iloc[j][['X','Y']]-cell_view.iloc[i][['X','Y']]))\n",
    "    distance_list_list = distance_list_list + distance_list\n",
    "    distance_list_list_2.append(distance_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a45f55",
   "metadata": {},
   "source": [
    "Calculate the adjency matrix, using the previously defined distance matrix.\n",
    "After this normlized the matrix and make a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d617c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import pickle\n",
    "import scipy.linalg\n",
    "distance_array = np.array(distance_list_list)\n",
    "for threshold in [140]:#[100,140,180,210,220,260]:#range (210,211):#(100,400,40):\n",
    "    num_big = np.where(distance_array<threshold)[0].shape[0]\n",
    "    print (threshold,num_big,str(num_big/(913*2)))\n",
    "    distance_matrix_threshold_I_list = []\n",
    "    distance_matrix_threshold_W_list = []\n",
    "    from sklearn.metrics.pairwise import euclidean_distances\n",
    "    for view_num in range (7):\n",
    "        cell_view = cell_view_list[view_num]\n",
    "        distance_matrix = euclidean_distances(cell_view[['X','Y']], cell_view[['X','Y']])\n",
    "        distance_matrix_threshold_I = np.zeros(distance_matrix.shape)\n",
    "        distance_matrix_threshold_W = np.zeros(distance_matrix.shape)\n",
    "        for i in range(distance_matrix_threshold_I.shape[0]):\n",
    "            for j in range(distance_matrix_threshold_I.shape[1]):\n",
    "                if distance_matrix[i,j] <= threshold and distance_matrix[i,j] > 0:\n",
    "                    distance_matrix_threshold_I[i,j] = 1\n",
    "                    distance_matrix_threshold_W[i,j] = distance_matrix[i,j]\n",
    "        distance_matrix_threshold_I_list.append(distance_matrix_threshold_I)\n",
    "        distance_matrix_threshold_W_list.append(distance_matrix_threshold_W)\n",
    "    whole_distance_matrix_threshold_I = scipy.linalg.block_diag(distance_matrix_threshold_I_list[0],\n",
    "                                                                distance_matrix_threshold_I_list[1],\n",
    "                                                                distance_matrix_threshold_I_list[2],\n",
    "                                                                distance_matrix_threshold_I_list[3],\n",
    "                                                                distance_matrix_threshold_I_list[4],\n",
    "                                                                distance_matrix_threshold_I_list[5],\n",
    "                                                                distance_matrix_threshold_I_list[6])\n",
    "    ############### get normalized sparse adjacent matrix\n",
    "    distance_matrix_threshold_I_N = normalized_adjacency(whole_distance_matrix_threshold_I)\n",
    "    # distance_matrix_threshold_I_N = np.float32(whole_distance_matrix_threshold_I) ## do not normalize adjcent matrix\n",
    "    distance_matrix_threshold_I_N = np.float32(whole_distance_matrix_threshold_I)\n",
    "    distance_matrix_threshold_I_N_crs = sparse.csr_matrix(distance_matrix_threshold_I_N)\n",
    "    with open(current_path+'/seqfish_plus/whole_FOV_distance_I_N_crs_'+str(threshold), 'wb') as fp:\n",
    "        pickle.dump(distance_matrix_threshold_I_N_crs, fp)\n",
    "    distance_matrix_threshold_I_N = np.float32(whole_distance_matrix_threshold_I) ## do not normalize adjcent matrix\n",
    "    distance_matrix_threshold_I_N_crs = sparse.csr_matrix(distance_matrix_threshold_I_N)\n",
    "    with open(current_path+'/seqfish_plus/whole_FOV_distance_I_N_crs_'+str(threshold), 'wb') as fp:\n",
    "        pickle.dump(distance_matrix_threshold_I_N, fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53def63",
   "metadata": {},
   "source": [
    "Now we look at the ligands and receptor list. We generate pairs ligand - receptor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f47145",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########### read ligand receptor database\n",
    "ligand_list = pd.read_csv(current_path+'/LR_database/ligand_list2.txt',header  = None)\n",
    "receptor_list = pd.read_csv(current_path+'/LR_database/receptor_list2.txt',header  = None)\n",
    "LR_pairs = pd.read_csv(current_path+'/LR_database/ligand_receptor_pairs2.txt',header  = None,sep ='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ea5d61",
   "metadata": {},
   "source": [
    "Then we  look at the gene counts. Add a 1 in all of them so we can normalize/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5bcd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "cortex_svz_counts = pd.read_csv(current_path+'/seqfish_plus/cortex_svz_counts.csv')\n",
    "cortex_svz_counts_N = cortex_svz_counts.div(cortex_svz_counts.sum(axis=1)+1, axis='rows')*10**4\n",
    "cortex_svz_counts_N.columns =[i.lower() for i in list(cortex_svz_counts_N)] ## gene expression normalization\n",
    "cortex_svz_cellcentroids = pd.read_csv(current_path+'/seqfish_plus/cortex_svz_cellcentroids.csv')\n",
    "# cortex_svz_counts_N_FOV = cortex_svz_counts_N\n",
    "#######################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b40e47c",
   "metadata": {},
   "source": [
    "Now we filter the receptor-ligand list by keeping the genes that are in the counts. \n",
    "After this we create a dictionary with the following format. KEY = ligand, VALUE = receptor to that ligand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b596aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gene_list =[i.lower() for i in list(cortex_svz_counts)]\n",
    "\n",
    "non_LR_list = [i for i in gene_list if i not in list(ligand_list.iloc[:,0]) and i not in list(receptor_list.iloc[:,0])]\n",
    "ovlp_ligand_list = [i for i in gene_list if i in list(ligand_list.iloc[:,0])]\n",
    "ovlp_receptor_list = [i for i in gene_list if i in list(receptor_list.iloc[:,0])]\n",
    "\n",
    "count = 0\n",
    "h_LR = defaultdict(list)\n",
    "for LR_pair_index in range(LR_pairs.shape[0]):\n",
    "    ligand, receptor =  LR_pairs.iloc[LR_pair_index]\n",
    "    if ligand in gene_list and receptor in gene_list:\n",
    "        h_LR[ligand].append(receptor)\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bce1c08",
   "metadata": {},
   "source": [
    "This function will create a matrix with \"true\" and \"false\" pairs of receptor-ligand relationships.\n",
    "Based on the gene counts for each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3b97ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_LR_pairs (h_LR_original,sub_ligand_list, sub_receptor_list,cortex_svz_counts_N):\n",
    "    h_LR = defaultdict(list)\n",
    "    for ligand in h_LR_original.keys():\n",
    "        if ligand in sub_ligand_list:\n",
    "            for receptor in h_LR_original[ligand]:\n",
    "                if receptor in sub_receptor_list:\n",
    "                    h_LR[ligand].append(receptor)\n",
    "    import random\n",
    "    random.seed(0)\n",
    "    count = 0\n",
    "    gene_pair_list  = []\n",
    "    X_data = []\n",
    "    Y_data = []\n",
    "    sub_ligand_list_ovlp = list(h_LR.keys())\n",
    "    for ligand in sub_ligand_list_ovlp:\n",
    "        for receptor in h_LR[ligand]:\n",
    "            gene_pair_list.append(ligand + '\\t' + receptor)\n",
    "            cell_LR_expression = np.array(cortex_svz_counts_N[[ligand, receptor]]) # postive sample\n",
    "            X_data.append(cell_LR_expression)\n",
    "            Y_data.append(1)\n",
    "            ############## get negative samples\n",
    "            non_pair_receptor_list = [i for i in sub_receptor_list if i not in h_LR[ligand]]\n",
    "            random.seed(count)\n",
    "            random_receptor = random.sample(non_pair_receptor_list, 1)[0]\n",
    "            gene_pair_list.append(ligand + '\\t' + random_receptor)\n",
    "            cell_LR_expression = np.array(cortex_svz_counts_N[[ligand, random_receptor]])\n",
    "            X_data.append(cell_LR_expression)\n",
    "            Y_data.append(0)\n",
    "            count = count + 1\n",
    "    ligand_record = sub_ligand_list_ovlp[0]\n",
    "    gene_pair_index = [0]\n",
    "    count = 0\n",
    "    for gene_pair in gene_pair_list:\n",
    "        ligand = gene_pair.split('\\t')[0]\n",
    "        if ligand == ligand_record:\n",
    "            count = count + 1\n",
    "        else:\n",
    "            gene_pair_index.append(count)\n",
    "            ligand_record = ligand\n",
    "            count = count + 1\n",
    "    gene_pair_index.append(count)\n",
    "    X_data_array = np.array(X_data)\n",
    "    Y_data_array = np.array(Y_data)\n",
    "    gene_pair_list_array = np.array(gene_pair_list)\n",
    "    gene_pair_index_array = np.array(gene_pair_index)\n",
    "    return (X_data_array,Y_data_array,gene_pair_list_array,gene_pair_index_array) ## x data, y data, gene pair name, index to separate pairs by ligand genes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e52ab01",
   "metadata": {},
   "source": [
    "We do ten matrices like this, divide them on training and testing. For Y is 1 if that's a true relationship or 0 if its not. \n",
    "Create files with this matrices, plus the array and gene pairs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c237e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## ten fold cross validation data generation\n",
    "ovlp_ligand_list_cons = ovlp_ligand_list\n",
    "ovlp_receptor_list_cons = ovlp_receptor_list\n",
    "import random\n",
    "random.seed(1)\n",
    "ovlp_ligand_list = random.sample(ovlp_ligand_list_cons,len(ovlp_ligand_list))\n",
    "random.seed(1)\n",
    "ovlp_receptor_list = random.sample(ovlp_receptor_list_cons,len(ovlp_receptor_list))\n",
    "for test_indel in range(1,11): ################## ten fold cross validation\n",
    "    print (test_indel)\n",
    "    ######### completely separate ligand and recpetor genes as mutually  exclusive train and test set\n",
    "    whole_ligand_index = [i for i in range(len(ovlp_ligand_list))]\n",
    "    test_ligand = [i for i in range (int(np.ceil((test_indel-1)*0.1*len(ovlp_ligand_list))),int(np.ceil(test_indel*0.1*len(ovlp_ligand_list))))]\n",
    "    train_ligand= [i for i in whole_ligand_index if i not in test_ligand]\n",
    "    whole_receptor_index = [i for i in range(len(ovlp_receptor_list))]\n",
    "    test_receptor = [i for i in range(int(np.ceil((test_indel - 1) * 0.1 * len(ovlp_receptor_list))),int(np.ceil(test_indel * 0.1 * len(ovlp_receptor_list))))]\n",
    "    train_receptor = [i for i in whole_receptor_index if i not in test_receptor]\n",
    "    X_data_array_train, Y_data_array_train, gene_pair_list_array_train, gene_pair_index_array_train = generate_LR_pairs (h_LR,np.array(ovlp_ligand_list)[train_ligand], np.array(ovlp_receptor_list)[train_receptor],cortex_svz_counts_N)\n",
    "    X_data_array_test, Y_data_array_test, gene_pair_list_array_test, gene_pair_index_array_test = generate_LR_pairs(h_LR, np.array(ovlp_ligand_list)[test_ligand], np.array(ovlp_receptor_list)[test_receptor], cortex_svz_counts_N)\n",
    "    if not os.path.isdir(current_path + '/rand_1_10fold/'):\n",
    "        os.makedirs(current_path + '/rand_1_10fold/')\n",
    "    np.save(current_path+'/rand_1_10fold/'+str(test_indel)+'_train_X_data_array.npy', X_data_array_train)\n",
    "    np.save(current_path+'/rand_1_10fold/'+str(test_indel)+'_train_Y_data_array.npy', Y_data_array_train)\n",
    "    np.save(current_path+'/rand_1_10fold/'+str(test_indel)+'_train_gene_pair_list_array.npy', gene_pair_list_array_train)\n",
    "    np.save(current_path+'/rand_1_10fold/'+str(test_indel)+'_train_gene_pair_index_array.npy', gene_pair_index_array_train)\n",
    "    np.save(current_path+'/rand_1_10fold/' + str(test_indel) + '_test_X_data_array.npy',X_data_array_test)\n",
    "    np.save(current_path+'/rand_1_10fold/' + str(test_indel) + '_test_Y_data_array.npy',Y_data_array_test)\n",
    "    np.save(current_path+'/rand_1_10fold/' + str(test_indel) + '_test_gene_pair_list_array.npy',gene_pair_list_array_test)\n",
    "    np.save(current_path+'/rand_1_10fold/' + str(test_indel) + '_test_gene_pair_index_array.npy',gene_pair_index_array_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daea02eb",
   "metadata": {},
   "source": [
    "### How does the data look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c8ec919",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indel=1\n",
    "X_data_train = np.load(current_path+'/rand_1_10fold/'+str(test_indel)+'_train_X_data_array.npy')\n",
    "Y_data_train = np.load(current_path+'/rand_1_10fold/'+str(test_indel)+'_train_Y_data_array.npy')\n",
    "gene_pair_index_train = np.load(current_path+'/rand_1_10fold/'+str(test_indel)+'_train_gene_pair_list_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de2999f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1772, 913, 2)\n",
      "[[0.89493467 0.        ]\n",
      " [2.17959895 0.        ]\n",
      " [1.58453494 0.        ]\n",
      " ...\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_data_train.shape)\n",
    "print((X_data_train)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256d93bf",
   "metadata": {},
   "source": [
    "X_data_train contains the gene expression for each pair of ligand-receptor. For each cell in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2629706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1772,)\n",
      "[1 0 1 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(Y_data_train.shape)\n",
    "print((Y_data_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28928b5",
   "metadata": {},
   "source": [
    "Y_data_train contains if the ligand-receptor relationship is true or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36957189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['adam10\\tepha3', 'adam10\\tjmjd6', 'adam12\\titga9', ...,\n",
       "       'wnt7a\\thtr1a', 'wnt7a\\tlrp6', 'wnt7a\\tgpr37l1'], dtype='<U17')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_pair_index_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806fe951",
   "metadata": {},
   "source": [
    "gene_pair_index_train has the names of the ligand-receptor columns from the previous data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb0784",
   "metadata": {},
   "source": [
    "We have the same data for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e61068",
   "metadata": {},
   "source": [
    "### Future directions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b3fb2",
   "metadata": {},
   "source": [
    "With this input is possible to create a graph convolution neural network. The graph would have the shape of the adjency matrix. And as input the matrices previusly shown. I will be possible to predict given the adjenency matrix wether or not two cells were interactiong via their ligand-receptor pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c64a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the structure using spektral:\n",
    "\n",
    "# Model definition\n",
    "    X_in = Input(shape=(N, F))\n",
    "    # Pass A as a fixed tensor, otherwise Keras will complain about inputs of\n",
    "    # different rank.\n",
    "    A_in = Input(tensor=sp_matrix_to_sp_tensor(fltr))\n",
    "\n",
    "    graph_conv = GraphConv(32,activation='elu',kernel_regularizer=l2(l2_reg),use_bias=True)([X_in, A_in])\n",
    "    graph_conv = GraphConv(32,activation='elu',kernel_regularizer=l2(l2_reg),use_bias=True)([graph_conv, A_in])\n",
    "    flatten = Flatten()(graph_conv)\n",
    "    fc = Dense(512, activation='relu')(flatten)\n",
    "    output = Dense(n_out, activation='sigmoid')(fc)\n",
    "\n",
    "    # Build model\n",
    "    model = Model(inputs=[X_in, A_in], outputs=output)\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['acc'])\n",
    "    model.summary()\n",
    "    \n",
    "     model.fit(X_train,y_train,batch_size=batch_size,validation_data=validation_data,epochs=epochs,callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
